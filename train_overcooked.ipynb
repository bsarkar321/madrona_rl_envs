{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Setup: Change the runtime type to use a T4 GPU (free colab tier). Run the next 5 cells to install dependencies for the notebook. The first cell installs CUDA 12, which contains the JIT compilation needed for madrona (10 mins). The second and third cells download the git repo (3 mins). The fourth cell compiles the C++ code for the environments (5 mins). The fifth cell installs python packages (0.5 min)."
      ],
      "metadata": {
        "id": "s-DeGKpTCsOu"
      },
      "id": "s-DeGKpTCsOu"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip uninstall -y build\n",
        "\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\n",
        "!sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda-repo-ubuntu2004-12-1-local_12.1.1-530.30.02-1_amd64.deb\n",
        "!sudo dpkg -i cuda-repo-ubuntu2004-12-1-local_12.1.1-530.30.02-1_amd64.deb\n",
        "!sudo cp /var/cuda-repo-ubuntu2004-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/\n",
        "!sudo DEBIAN_FRONTEND=noninteractive apt-get update\n",
        "!sudo DEBIAN_FRONTEND=noninteractive apt-get -y install cuda"
      ],
      "metadata": {
        "id": "XucDVoSyyph_"
      },
      "id": "XucDVoSyyph_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "!ls /usr/local/\n",
        "%cd /content\n",
        "!rm -rf madrona_rl_envs"
      ],
      "metadata": {
        "id": "pFr3B0Zz5s-w"
      },
      "id": "pFr3B0Zz5s-w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bca83f6",
      "metadata": {
        "scrolled": true,
        "id": "5bca83f6"
      },
      "outputs": [],
      "source": [
        "%pip install torch numpy tensorboard flask onnx onnx_tf tensorflow tensorflow_probability tensorflowjs\n",
        "!git clone https://github.com/bsarkar321/madrona_rl_envs\n",
        "%cd madrona_rl_envs\n",
        "!git submodule update --init --recursive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf build\n",
        "!mkdir build && cd build && cmake -D CUDAToolkit_ROOT=/usr/local/cuda -D MADRONA_REQUIRE_CUDA=ON .. && make -j && cd .."
      ],
      "metadata": {
        "id": "757syfQmCqN8"
      },
      "id": "757syfQmCqN8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a971671e",
      "metadata": {
        "id": "a971671e"
      },
      "outputs": [],
      "source": [
        "%pip install -e .\n",
        "%pip install -e PantheonRL/overcookedgym/human_aware_rl/overcooked_ai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ff30b5f",
      "metadata": {
        "id": "7ff30b5f"
      },
      "source": [
        "**Restart runtime here!** Then continue running the next blocks.\n",
        "\n",
        "In this section, we will actually train an Overcooked agent from scratch using MAPPO."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/madrona_rl_envs"
      ],
      "metadata": {
        "id": "rQKD7REV5NxU"
      },
      "id": "rQKD7REV5NxU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e630cd",
      "metadata": {
        "id": "08e630cd"
      },
      "outputs": [],
      "source": [
        "%env MADRONA_MWGPU_KERNEL_CACHE=/tmp/madrona_over_cache\n",
        "import os\n",
        "import overcooked_ai_py\n",
        "from train.MAPPO.main_player import MainPlayer\n",
        "\n",
        "from train.config import get_config\n",
        "from pathlib import Path\n",
        "\n",
        "from train.env_utils import generate_env\n",
        "\n",
        "from train.partner_agents import CentralizedAgent\n",
        "\n",
        "import torch\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30118915",
      "metadata": {
        "id": "30118915"
      },
      "outputs": [],
      "source": [
        "args = get_config().parse_args(\"\")\n",
        "args.num_env_steps = 8000000\n",
        "args.pop_size = 1\n",
        "args.episode_length = 200\n",
        "args.env_length = 200\n",
        "args.env_name = \"overcooked\"\n",
        "args.seed = 1\n",
        "args.over_layout = \"simple\"\n",
        "args.run_dir = \"sp\"\n",
        "args.restored = 0\n",
        "args.cuda = True\n",
        "\n",
        "args.n_rollout_threads = 800\n",
        "args.ppo_epoch = 7\n",
        "args.layer_N = 1\n",
        "args.hidden_size = 64\n",
        "args.lr = 1e-2\n",
        "args.critic_lr = 1e-2\n",
        "args.entropy_coef = 0.0\n",
        "args.linear_lr_decay = False\n",
        "\n",
        "args.use_baseline = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ba74bd5",
      "metadata": {
        "id": "2ba74bd5"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() and args.cuda else 'cpu'\n",
        "print(device)\n",
        "\n",
        "# the first time this runs will take about a minute because of jit compilation; future runs are faster\n",
        "envs = generate_env(args.env_name, args.n_rollout_threads, args.over_layout, use_env_cpu=(device=='cpu'), use_baseline=args.use_baseline)\n",
        "\n",
        "args.hanabi_name = args.over_layout if args.env_name == 'overcooked' else args.env_name\n",
        "\n",
        "run_dir = (\n",
        "        \"train/\"\n",
        "        + args.hanabi_name\n",
        "        + \"/results/\"\n",
        "        + (args.run_dir)\n",
        "        + \"/\"\n",
        "        + str(args.seed)\n",
        "    )\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "with open(run_dir + \"/\" + \"args.txt\", \"w\", encoding=\"UTF-8\") as file:\n",
        "    file.write(str(args))\n",
        "config = {\n",
        "    'all_args': args,\n",
        "    'envs': envs,\n",
        "    'device': device,\n",
        "    'num_agents': 2,\n",
        "    'run_dir': Path(run_dir)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ce1ef7",
      "metadata": {
        "scrolled": true,
        "id": "d6ce1ef7"
      },
      "outputs": [],
      "source": [
        "# If you want to rerun this, remember to also run the two cells above so the environment is regenerated\n",
        "# If you encounter an out of memory error, restart the runtime and start from the cell after \"Restart runtime here!\" above.\n",
        "start = time.time()\n",
        "ego = MainPlayer(config)\n",
        "partner = CentralizedAgent(ego, 1)\n",
        "envs.add_partner_agent(partner)\n",
        "ego.run()\n",
        "end = time.time()\n",
        "print(f\"Total time taken: {end - start} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cc31582",
      "metadata": {
        "id": "3cc31582"
      },
      "source": [
        "Testing quality of trained agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d90451",
      "metadata": {
        "id": "e1d90451"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.distributions.categorical import Categorical\n",
        "\n",
        "\n",
        "class Policy(nn.Module):\n",
        "\n",
        "    def __init__(self, actor):\n",
        "        super(Policy, self).__init__()\n",
        "\n",
        "        self.base = actor.base.cnn.cnn\n",
        "        self.act_layer = actor.act\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = x.to(dtype=torch.float)\n",
        "        x = self.base(x.permute((0, 3, 1, 2)))\n",
        "        x = self.act_layer(x, deterministic=True)\n",
        "        return x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9080b5ed",
      "metadata": {
        "id": "9080b5ed"
      },
      "outputs": [],
      "source": [
        "run_dir = Path(run_dir)\n",
        "args.model_dir = str(run_dir / 'models')\n",
        "\n",
        "config = {\n",
        "    'all_args': args,\n",
        "    'envs': envs,\n",
        "    'device': device,\n",
        "    'num_agents': 2,\n",
        "    'run_dir': run_dir\n",
        "}\n",
        "\n",
        "ego = MainPlayer(config)\n",
        "ego.restore()\n",
        "torch_network = Policy(ego.policy.actor)\n",
        "\n",
        "actions = torch.zeros((2, args.n_rollout_threads, 1), dtype=int, device=device)\n",
        "\n",
        "state1, state2 = envs.n_reset()\n",
        "scores = torch.zeros(args.n_rollout_threads, device=device)\n",
        "for i in range(args.env_length):\n",
        "    actions[0, :, :] = torch_network(state1.obs)\n",
        "    actions[1, :, :] = torch_network(state2.obs)\n",
        "    (state1, state2), reward, _, _ = envs.n_step(actions)\n",
        "    scores += reward[0, :]\n",
        "score_vals, counts = torch.unique(scores, return_counts=True)\n",
        "print({x.item() : y.item() for x, y in zip(score_vals, counts)})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00aea08b",
      "metadata": {
        "id": "00aea08b"
      },
      "source": [
        "Viewing and interacting with trained agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507363e5",
      "metadata": {
        "id": "507363e5"
      },
      "outputs": [],
      "source": [
        "import onnx\n",
        "from onnx_tf.backend import prepare\n",
        "\n",
        "class SimplePolicy(nn.Module):\n",
        "\n",
        "    def __init__(self, actor):\n",
        "        super(SimplePolicy, self).__init__()\n",
        "\n",
        "        self.base = actor.base.cnn.cnn\n",
        "        self.act_layer = actor.act.action_out.linear\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.base(x.permute((0, 3, 1, 2)))\n",
        "        x = self.act_layer(x)\n",
        "        return nn.functional.softmax(x, dim=1)\n",
        "\n",
        "args.n_rollout_threads = 1\n",
        "\n",
        "s_envs = generate_env(args.env_name, args.n_rollout_threads, args.over_layout)\n",
        "\n",
        "args.hanabi_name = args.over_layout if args.env_name == 'overcooked' else args.env_name\n",
        "\n",
        "torch_network = SimplePolicy(ego.policy.actor)\n",
        "\n",
        "vobs, _ = s_envs.n_reset()\n",
        "obs = vobs.obs.to(dtype=torch.float)\n",
        "\n",
        "print(\"*\" * 20, \" TORCH \", \"*\" * 20)\n",
        "\n",
        "print(torch_network)\n",
        "\n",
        "print(obs.shape)\n",
        "\n",
        "print(torch_network(obs))\n",
        "\n",
        "print(\"*\" * 20, \" ONNX \", \"*\" * 20)\n",
        "onnx_model_path = str(run_dir / \"models\" / f\"MAPPO_{args.over_layout}_agent.onnx\")\n",
        "\n",
        "input_name = 'input'  # 'ppo_agent/ppo2_model/Ob'\n",
        "\n",
        "torch.onnx.export(torch_network,\n",
        "                  obs,\n",
        "                  onnx_model_path,\n",
        "                  export_params=True,\n",
        "                  input_names=[input_name],\n",
        "                  output_names=['output'],\n",
        "                  opset_version=10)\n",
        "\n",
        "onnx_model = onnx.load(onnx_model_path)\n",
        "\n",
        "print(onnx_model.graph.input[0])\n",
        "\n",
        "onnx.checker.check_model(onnx_model)\n",
        "\n",
        "print(\"*\" * 20, \" TF \", \"*\" * 20)\n",
        "tf_rep = prepare(onnx_model)\n",
        "tf_model_dir = str(run_dir / 'models' / f'MAPPO_{args.over_layout}_agent')\n",
        "tf_rep.export_graph(tf_model_dir)\n",
        "\n",
        "tfjs_model_dir = f\"overcooked_demo/static/assets/MAPPO_{args.over_layout}_agent\"\n",
        "tfjs_convert_command = f\"\"\"tensorflowjs_converter\n",
        "                 --input_format=tf_saved_model\n",
        "                 --output_format=tfjs_graph_model\n",
        "                 --signature_name=serving_default\n",
        "                 --saved_model_tags=serve\n",
        "                 \"{tf_model_dir}\"\n",
        "                 \"{tfjs_model_dir}\"\n",
        "                 \"\"\"\n",
        "tfjs_convert_command = \" \".join(tfjs_convert_command.split())\n",
        "\n",
        "# This should only take about a minute in total. If it runs for longer, you may have to restart the runtime.\n",
        "# In this case, you would need to run all the cells after the one that says \"Restart runtime here!\" but you\n",
        "# can skip the cell for actually training the policy (since it is already saved to disk).\n",
        "os.system(tfjs_convert_command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only run this ONCE for a runtime instance\n",
        "\n",
        "# code to display on colab from https://stackoverflow.com/a/61504116\n",
        "%cd /content/madrona_rl_envs/overcooked_demo\n",
        "get_ipython().system_raw('python3 -m http.server 8888 &')\n",
        "%cd /content/madrona_rl_envs"
      ],
      "metadata": {
        "id": "eD3PGkTrpU2r"
      },
      "id": "eD3PGkTrpU2r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Javascript\n",
        "\n",
        "def show_port(port, height=900):\n",
        "  display(Javascript(\"\"\"\n",
        "  (async ()=>{\n",
        "    fm = document.createElement('iframe')\n",
        "    fm.src = await google.colab.kernel.proxyPort(%s)\n",
        "    fm.width = '95%%'\n",
        "    fm.height = '%d'\n",
        "    fm.frameBorder = 0\n",
        "    document.body.append(fm)\n",
        "  })();\n",
        "  \"\"\" % (port, height) ))\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(8888)\"))\n",
        "\n",
        "# displays the game in-line; you may have to wait for over a minute after this\n",
        "# line runs before it appears, since it is running through javascript on your\n",
        "# device\n",
        "show_port(8888)"
      ],
      "metadata": {
        "id": "mt-NvAou2Kk9"
      },
      "id": "mt-NvAou2Kk9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}